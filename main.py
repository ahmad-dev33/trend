import re
import json
from collections import Counter
from typing import List, Dict, Any, Optional, TypedDict, cast
from textblob import TextBlob
import requests
from bs4 import BeautifulSoup
from dotenv import load_dotenv

# ุชุญููู ูุชุบูุฑุงุช ุงูุจูุฆุฉ ูู ููู .env
load_dotenv()

# --- ุชุนุฑูู ุฃููุงุน ุงูุจูุงูุงุช ูุชุญุณูู ูุฑุงุกุฉ ุงูููุฏ ูุชูููู ุงูุฃุฎุทุงุก ---
class Post(TypedDict):
    platform: str
    title: str
    views: int
    likes: int
    url: str

class SentimentInfo(TypedDict):
    post: Post
    sentiment: float

class AnalysisResults(TypedDict):
    most_viewed: Post
    most_liked: Post
    most_loved: SentimentInfo
    most_hated: SentimentInfo
    top_keywords: List[tuple[str, int]]

def fetch_twitter_mock_data() -> List[Post]:
    """
    ูุฐู ุงูุฏุงูุฉ ุชููู ุจูุญุงูุงุฉ ุฌูุจ ุงูุจูุงูุงุช ูู ุชููุชุฑ ูููุตุงุช ุฃุฎุฑู (ุจุงุณุชุซูุงุก ููุชููุจ ุงูุฐู ูุชู ูุดุทู).
    ูู ุชุทุจูู ุญููููุ ุณุชููู ููุง ุจุงุณุชุฏุนุงุก ูุงุฌูุงุช ุจุฑูุฌูุฉ (APIs) ุญููููุฉ.
    """
    mock_posts: List[Post] = [
        {'platform': 'Twitter', 'title': 'ุฅุทูุงู ูุงุชู ุฌุฏูุฏ ุจููุฒุงุช ุซูุฑูุฉ ูุซูุฑ ุงูุฌุฏู', 'views': 500000, 'likes': 25000, 'url': 'https://twitter.com/status/xyz1'},
        {'platform': 'TikTok', 'title': 'ุชุญุฏู ุงูุทุจุฎ ุงูุฌุฏูุฏ ููุชุดุฑ ุจุณุฑุนุฉ', 'views': 8000000, 'likes': 950000, 'url': 'https://tiktok.com/v/def2'},
        {'platform': 'Facebook', 'title': 'ููุงุด ุญุงุฏ ุญูู ูุงููู ุงูุนูู ุงูุฌุฏูุฏ', 'views': 300000, 'likes': 8000, 'url': 'https://facebook.com/post/ghi3'},
        {'platform': 'Instagram', 'title': 'ุตูุฑ ูุฐููุฉ ูู ุญูู ุชูุฒูุน ุงูุฌูุงุฆุฒ', 'views': 1200000, 'likes': 250000, 'url': 'https://instagram.com/p/jkl4'},
        {'platform': 'Twitter', 'title': 'ูุดู ุฅุทูุงู ุตุงุฑูุฎ ูุถุงุฆู ูุณุจุจ ุฎูุจุฉ ุฃูู ูุจูุฑุฉ', 'views': 750000, 'likes': 12000, 'url': 'https://twitter.com/status/pqr6'},
    ]
    return mock_posts

def _parse_youtube_views(views_text: str) -> int:
    """
    ุฏุงูุฉ ูุณุงุนุฏุฉ ูุชุญููู ูุต ุนุฏุฏ ุงููุดุงูุฏุงุช ูู ููุชููุจ ุฅูู ุฑูู ุตุญูุญ.
    ูุซุงู: "1.2 ููููู ูุดุงูุฏุฉ" -> 1200000
    """
    # ุชูุธูู ุงููุต ูู ุงููููุงุช ูุงูุฑููุฒ ุบูุฑ ุงูุถุฑูุฑูุฉ
    cleaned_text = views_text.replace('ูุดุงูุฏุฉ', '').replace(',', '').strip()
    
    views = 0
    if 'ุฃูู' in cleaned_text:
        views = int(float(cleaned_text.replace('ุฃูู', '').strip()) * 1000)
    elif 'ููููู' in cleaned_text:
        views = int(float(cleaned_text.replace('ููููู', '').strip()) * 1000000)
    elif cleaned_text.isdigit():
        views = int(cleaned_text)
    
    return views

def scrape_youtube_trending() -> List[Post]:
    """
    ุชููู ูุฐู ุงูุฏุงูุฉ ุจูุดุท ุตูุญุฉ ุชุฑููุฏ ููุชููุจ ูุฌูุจ ุงูููุฏูููุงุช ุงูุฑุงุฆุฌุฉ.
    ุชุนุชูุฏ ูุฐู ุงูุทุฑููุฉ ุนูู ุจููุฉ ุตูุญุฉ ููุชููุจุ ููุฏ ุชุชููู ุนู ุงูุนูู ุฅุฐุง ุบูุฑ ููุชููุจ ุชุตููู ูููุนู.
    """
    print("ุฌุงุฑู ุฌูุจ ุชุฑููุฏ ููุชููุจ ุนู ุทุฑูู Web Scraping...")
    url = "https://www.youtube.com/feed/trending"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
        "Accept-Language": "ar-SA,ar;q=0.9,en-US;q=0.8,en;q=0.7"
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status() # ุงูุชุฃูุฏ ูู ูุฌุงุญ ุงูุทูุจ
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ุจูุงูุงุช ููุชููุจ ุบุงูุจุงู ูุง ุชููู ุถูู ูุชุบูุฑ JavaScript ูุณูู ytInitialData
        scripts = soup.find_all('script')
        data_script = None
        # Use a more robust way to find the script tag content
        for script in scripts:
            if script.string and 'ytInitialData' in str(script.string):
                data_script = str(script.string)
                break
        
        if not data_script:
            print("ูู ูุชู ุงูุนุซูุฑ ุนูู ุจูุงูุงุช ุงูุชุฑููุฏ ูู ุตูุญุฉ ููุชููุจ.")
            return [] # Return early if no data is found
            
        # ุงุณุชุฎูุงุต ุงูุฌุฒุก ุงูุฎุงุต ุจู JSON ูู ุงูุณูุฑุจุช
        json_data_str = data_script.split(' = ')[1]
        # ุฅุฒุงูุฉ ุงููุงุตูุฉ ุงูููููุทุฉ ูู ุงูููุงูุฉ ุฅุฐุง ูุฌุฏุช
        if json_data_str.endswith(';'):
            json_data_str = json_data_str[:-1]
            
        data: Dict[str, Any] = json.loads(json_data_str)
        
        # ุงููุณุงุฑ ุฅูู ุงูููุฏูููุงุช ูุฏ ูุชุบูุฑุ ูุฐุง ุงููุณุงุฑ ุตุญูุญ ุญุงููุงู. ูุณุชุฎุฏู try-except ููุชุนุงูู ูุน ุงูุชุบููุฑุงุช ุงููุญุชููุฉ.
        try:
            video_items = data['contents']['twoColumnBrowseResultsRenderer']['tabs'][0]['tabRenderer']['content']['sectionListRenderer']['contents'][0]['itemSectionRenderer']['contents'][0]['shelfRenderer']['content']['expandedShelfContentsRenderer']['items']
        except (KeyError, IndexError) as e:
            print(f"ูุดู ูู ุชุญููู ุจููุฉ ุจูุงูุงุช ููุชููุจุ ุฑุจูุง ุชุบูุฑ ุชุตููู ุงููููุน. ุงูุฎุทุฃ: {e}")
            return []
        
        youtube_trends: List[Post] = []
        for item in video_items:
            if 'videoRenderer' not in item:
                continue
            video = item['videoRenderer']
            views_text = video.get('viewCountText', {}).get('simpleText', '0')

            youtube_trends.append({
                'platform': 'YouTube',
                'title': video['title']['runs'][0]['text'],
                'views': _parse_youtube_views(views_text),
                'likes': 0, # ุงูุฅุนุฌุงุจุงุช ุบูุฑ ูุชููุฑุฉ ูุจุงุดุฑุฉ ูู ุตูุญุฉ ุงูุชุฑููุฏ
                'url': 'https://youtube.com/watch?v=' + video['videoId']
            })
        return youtube_trends

    except Exception as e:
        print(f"ุญุฏุซ ุฎุทุฃ ุฃุซูุงุก ุฌูุจ ุจูุงูุงุช ููุชููุจ: {e}")
        return []

def analyze_trends(posts: List[Post]) -> Optional[AnalysisResults]:
    """
    ุชููู ูุฐู ุงูุฏุงูุฉ ุจุชุญููู ูุงุฆูุฉ ุงูููุดูุฑุงุช ุงููุณุชููุฉ.
    """
    if not posts:
        print("ูุง ุชูุฌุฏ ุจูุงูุงุช ูุชุญููููุง.")
        return None

    print("ุฌุงุฑู ุชุญููู ุงูุจูุงูุงุช ุงููุณุชููุฉ...")

    # 1. ุชุญููู ุงููุดุงุนุฑ ููุนุซูุฑ ุนูู ุงููุญุชูู ุงูุฃูุซุฑ ุญุจุงู ููุฑุงููุฉ
    sentiments: List[SentimentInfo] = []
    for post in posts:
        # ุงุณุชุฎุฏุงู TextBlob ูุชุญููู ุงููุต. ุงููุทุจูุฉ (polarity) ุชุชุฑุงูุญ ูู -1 (ุณูุจู ุฌุฏุงู) ุฅูู +1 (ุฅูุฌุงุจู ุฌุฏุงู)
        sentiment = TextBlob(post['title']).sentiment.polarity
        sentiments.append({'post': post, 'sentiment': sentiment})
    
    # 2. ุงุณุชุฎุฑุงุฌ ุงููููุงุช ุงูููุชุงุญูุฉ ุงูุฃูุซุฑ ุงุณุชุฎุฏุงูุงู
    all_titles = ' '.join(p['title'] for p in posts)
    # ุชูุธูู ุงููุต ูู ุงูุฑููุฒ ุบูุฑ ุงููุฑุบูุจ ูููุง ูุชุญูููู ุฅูู ูููุงุช ุตุบูุฑุฉ
    words = re.findall(r'\b\w+\b', all_titles.lower())
    
    # ูุงุฆูุฉ ุจูููุงุช ุดุงุฆุนุฉ (stop words) ูุชุฌุงูููุง ูู ุงูุชุญููู
    # ููููู ุฅุถุงูุฉ ุงููุฒูุฏ ูู ุงููููุงุช ุงูุนุฑุจูุฉ ููุง
    stop_words = set(['ูู', 'ุนู', 'ูู', 'ู', 'ุฃู', 'ุฅูู', 'ูู', 'ูู', 'ูุฐุง', 'ูุฐู', 'ุฌุฏุง'])
    meaningful_words = [word for word in words if word not in stop_words and not word.isdigit()]
    
    # ุญุณุงุจ ุชูุฑุงุฑ ุงููููุงุช
    word_counts = Counter(meaningful_words)

    # 3. ุชุฌููุน ูู ุงููุชุงุฆุฌ ูู ูุงููุณ ูุงุญุฏ ููุธู
    analysis: AnalysisResults = {
        'most_viewed': sorted(posts, key=lambda p: p['views'], reverse=True)[0],
        'most_liked': sorted(posts, key=lambda p: p['likes'], reverse=True)[0],
        'most_loved': sorted(sentiments, key=lambda s: s['sentiment'], reverse=True)[0],
        'most_hated': sorted(sentiments, key=lambda s: s['sentiment'])[0],
        'top_keywords': word_counts.most_common(5)
    }

    return analysis

def display_results(analysis: Optional[AnalysisResults]) -> None:
    """
    ุชููู ูุฐู ุงูุฏุงูุฉ ุจุนุฑุถ ุงููุชุงุฆุฌ ุจุทุฑููุฉ ููุธูุฉ ูุณููุฉ ุงูููู.
    """
    if not analysis:
        return

    print("\n" + "="*40)
    print("๐ ุชูุฑูุฑ ุงูุชุฑููุฏุงุช ุนูู ููุงูุน ุงูุชูุงุตู ๐")
    print("="*40 + "\n")

    # ุนุฑุถ ุงููุชุงุฆุฌ ุงูุฑุฆูุณูุฉ
    mv = analysis['most_viewed']
    print(f"๐ฅ ุงูุฃูุซุฑ ูุดุงูุฏุฉ:")
    print(f"   - ุงูุนููุงู: \"{mv['title']}\"")
    print(f"   - ุงูููุตุฉ: {mv['platform']}")
    print(f"   - ุงููุดุงูุฏุงุช: {mv['views']:,}")
    print(f"   - ุงูุฑุงุจุท: {mv['url']}\n")

    ml = analysis['most_liked']
    # ุงูุชุญูู ูู ุฃู ููุงู ููุดูุฑุงุช ูุฏููุง ุฅุนุฌุงุจุงุช
    if ml['likes'] > 0:
        print(f"โค๏ธ ุงูุฃูุซุฑ ุฅุนุฌุงุจุงู:")
        print(f"   - ุงูุนููุงู: \"{ml['title']}\"")
        print(f"   - ุงูููุตุฉ: {ml['platform']}")
        print(f"   - ุงูุฅุนุฌุงุจุงุช: {ml['likes']:,}")
        print(f"   - ุงูุฑุงุจุท: {ml['url']}\n")

    # ุนุฑุถ ูุชุงุฆุฌ ุชุญููู ุงููุดุงุนุฑ
    loved = analysis['most_loved']
    print(f"๐ ุงูุชุฑููุฏ ุงูุฃูุซุฑ ุฅูุฌุงุจูุฉ (ุญุจุงู):")
    print(f"   - ุงูุนููุงู: \"{loved['post']['title']}\"")
    print(f"   - ุงูููุตุฉ: {loved['post']['platform']}")
    print(f"   - ุฏุฑุฌุฉ ุงูุฅูุฌุงุจูุฉ: {loved['sentiment']:.2f}")
    print(f"   - ุงูุฑุงุจุท: {loved['post']['url']}\n")

    hated = analysis['most_hated']
    print(f"๐ ุงูุชุฑููุฏ ุงูุฃูุซุฑ ุณูุจูุฉ (ูุฑูุงู):")
    print(f"   - ุงูุนููุงู: \"{hated['post']['title']}\"")
    print(f"   - ุงูููุตุฉ: {hated['post']['platform']}")
    print(f"   - ุฏุฑุฌุฉ ุงูุณูุจูุฉ: {hated['sentiment']:.2f}")
    print(f"   - ุงูุฑุงุจุท: {hated['post']['url']}\n")

    # ุนุฑุถ ุงููููุงุช ุงูููุชุงุญูุฉ
    keywords = analysis['top_keywords']
    if keywords:
        print("๐ ุงููููุงุช ุงูููุชุงุญูุฉ ุงูุฃูุซุฑ ุงุณุชุฎุฏุงูุงู:")
        for keyword, count in keywords:
            print(f"   - \"{keyword}\" (ุชูุฑุฑุช {count} ูุฑุงุช)")

    print("\n" + "="*40)
    print("ุงูุชูู ุงูุชูุฑูุฑ.")
    print("="*40)

def fetch_all_trends() -> List[Post]:
    """
    ุฏุงูุฉ ุฑุฆูุณูุฉ ูุชุฌููุน ุงูุชุฑููุฏุงุช ูู ูู ุงููุตุงุฏุฑ ุงููุชุงุญุฉ.
    ุชุชุฌุงูุฒ ุงููุตุงุฏุฑ ุงูุชู ุชูุดู ูุชููู ุจุงูุจุงูู.
    """
    all_posts: List[Post] = []
    print("="*40)
    print("ุจุฏุก ุนูููุฉ ุฌูุจ ุงูุชุฑููุฏุงุช ูู ุฌููุน ุงููุตุงุฏุฑ...")
    
    # ุงููุตุฏุฑ ุงูุฃูู: ููุชููุจ (ุนุจุฑ ูุดุท ุงูููุจ)
    all_posts.extend(scrape_youtube_trending())
    
    # ุงููุตุฏุฑ ุงูุซุงูู: ุชููุชุฑ (ุจูุงูุงุช ููููุฉ ุญุงููุงู)
    # ููููู ุงุณุชุจุฏุงููุง ุจุฏุงูุฉ ุชุณุชุฎุฏู API ุญูููู
    all_posts.extend(fetch_twitter_mock_data())
    
    print(f"\nุชู ุฌูุจ ูุง ูุฌููุนู {len(all_posts)} ููุดูุฑุงู ูู ุฌููุน ุงููุตุงุฏุฑ.")
    return all_posts

if __name__ == "__main__":
    # 1. ุฌูุจ ุงูุจูุงูุงุช
    social_media_posts: List[Post] = fetch_all_trends()
    
    # 2. ุชุญููู ุงูุจูุงูุงุช
    analyzed_data: Optional[AnalysisResults] = analyze_trends(social_media_posts)
    
    # 3. ุนุฑุถ ุงููุชุงุฆุฌ
    display_results(analyzed_data)
